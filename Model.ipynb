{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.random as rand\n",
    "from itertools import islice\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import (GradientBoostingClassifier, \n",
    "                              AdaBoostClassifier,\n",
    "                              RandomForestClassifier)\n",
    "import sklearn.datasets as datasets\n",
    "import sklearn.model_selection as cv\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.ensemble.partial_dependence import partial_dependence, plot_partial_dependence\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (9, 7)\n",
    "# from IPython.display import HTML\n",
    "from DataCleaning import data_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_cleaning('data/churn_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cv.train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=2, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=100,\n                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n                       warm_start=False)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_scores(X, y, estimator, p=False, train=False):\n",
    "    if train:\n",
    "        scores = cv.cross_validate(estimator, X, y, scoring=['accuracy', 'precision', 'recall', 'neg_log_loss'], cv=5)\n",
    "        acc = np.mean(scores['test_accuracy'])\n",
    "        precision = np.mean(scores['test_precision'])\n",
    "        recall = np.mean(scores['test_recall'])\n",
    "        log_loss = -np.mean(scores['test_neg_log_loss'])\n",
    "    else:\n",
    "        y_hat = estimator.predict(X)\n",
    "        acc = metrics.accuracy_score(y, y_hat)\n",
    "        precision = metrics.precision_score(y, y_hat)\n",
    "        recall = metrics.recall_score(y, y_hat)\n",
    "        log_loss = metrics.log_loss(y, estimator.predict_proba(X))\n",
    "    if p:\n",
    "        print (\"Accuracy: {0:2.3} | Precision: {1:2.3} | Recall: {2:2.3} | Log_loss: {3:2.3}\".format(\n",
    "                                                                    acc, precision, recall, log_loss))                                                           \n",
    "    else:\n",
    "        return acc, precision, recall, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train_Data\nAccuracy: 0.728 | Precision: 0.754 | Recall: 0.413 | Log_loss: 0.558\n"
    }
   ],
   "source": [
    "print ('Train_Data')\n",
    "model_scores(X_train, y_train, rfc, p=True, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Test_Data\nAccuracy: 0.73 | Precision: 0.75 | Recall: 0.414 | Log_loss: 0.558\n"
    }
   ],
   "source": [
    "print ('Test_Data')\n",
    "model_scores(X_test, y_test, rfc, p=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6242"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "1 - y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "null\n",
    "churn = .625\n",
    "retain = .375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[5751,  516],\n       [2189, 1544]])"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, rfc.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42427440633245384"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1608 / (2182+1608)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression(solver='lbfgs')\n",
    "LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5283,  927],\n",
       "       [1876, 1914]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, LR.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7197"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, LR.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_y = np.ones(len(y_test*y_test.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 6210],\n",
       "       [   0, 3790]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, null_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_grid = {'fit_intercept': [True, False],\n",
    "                            'solver': ['lbfgs', 'saga'],\n",
    "                            'random_state': [2]}\n",
    "\n",
    "lr_gridsearch = cv.GridSearchCV(LogisticRegression(),\n",
    "                                logistic_regression_grid,\n",
    "                                n_jobs=-1,\n",
    "                                verbose=True,\n",
    "                                scoring='neg_log_loss',\n",
    "                                cv=5)\n",
    "lr_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:        \", lr_gridsearch.best_params_)\n",
    "\n",
    "lr_best_estimator = lr_gridsearch.best_estimator_\n",
    "print('best estimator:         ', best_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log_loss of best estimator:   0.5050131926121372\n"
     ]
    }
   ],
   "source": [
    "lr_best_prediction = best_estimator.predict(X_test)\n",
    "print('Log_loss of best estimator:  ', metrics.recall_score(y_test, best_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_grid = {'max_depth': [1, 2, None],\n",
    "                      'max_features': ['sqrt'],\n",
    "                      'min_samples_split': [2, 4],\n",
    "                      'min_samples_leaf': [1, 2, 4],\n",
    "                      'bootstrap': [True],\n",
    "                      'n_estimators': [80, 90, 100],\n",
    "                      'random_state': [2]}\n",
    "\n",
    "rf_gridsearch = cv.GridSearchCV(RandomForestClassifier(),\n",
    "                             random_forest_grid,\n",
    "                             n_jobs=-1,\n",
    "                             verbose=True,\n",
    "                             scoring='neg_log_loss',\n",
    "                             cv=5)\n",
    "rf_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:         {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100, 'random_state': 2}\n",
      "best estimator:          LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=2, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(\"best parameters:        \", rf_gridsearch.best_params_)\n",
    "\n",
    "rf_best_estimator = rf_gridsearch.best_estimator_\n",
    "print('best estimator:         ', best_estimator)\n",
    "\n",
    "rf_best_prediction = best_estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of estimator:   0.6617414248021108\n"
     ]
    }
   ],
   "source": [
    "print('Score of estimator:  ', metrics.recall_score(y_test, best_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Parameter values for parameter (learning_rate) need to be a sequence(but not a string) or np.ndarray.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-aae7a2f236ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m                              \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                              \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_log_loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                              cv=5)\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mgbr_gridsearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, estimator, param_grid, scoring, n_jobs, iid, refit, cv, verbose, pre_dispatch, error_score, return_train_score)\u001b[0m\n\u001b[1;32m   1145\u001b[0m             return_train_score=return_train_score)\n\u001b[1;32m   1146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         \u001b[0m_check_param_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_check_param_grid\u001b[0;34m(param_grid)\u001b[0m\n\u001b[1;32m    384\u001b[0m                 raise ValueError(\"Parameter values for parameter ({0}) need \"\n\u001b[1;32m    385\u001b[0m                                  \u001b[0;34m\"to be a sequence(but not a string) or\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m                                  \" np.ndarray.\".format(name))\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Parameter values for parameter (learning_rate) need to be a sequence(but not a string) or np.ndarray."
     ]
    }
   ],
   "source": [
    "gradient_boosted_grid = {'max_depth': [1, 2, None],\n",
    "                         'max_features': ['sqrt', 'log2', None],\n",
    "                         'min_samples_split': [2, 4],\n",
    "                         'min_samples_leaf': [1, 2, 4],\n",
    "                         'n_estimators': [75, 100],\n",
    "                         'learning_rate': [.1],\n",
    "                         'random_state': [2]}\n",
    "\n",
    "gbr_gridsearch = cv.GridSearchCV(GradientBoostingClassifier(),\n",
    "                             gradient_boosted_grid,\n",
    "                             n_jobs=-1,\n",
    "                             verbose=True,\n",
    "                             scoring='neg_log_loss',\n",
    "                             cv=5)\n",
    "gbr_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:        \", gbr_gridsearch.best_params_)\n",
    "\n",
    "gbr_best_estimator = gbr_gridsearch.best_estimator_\n",
    "print('best estimator:         ', best_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_best_prediction = best_estimator.predict(X_test)\n",
    "print('Log_loss of best estimator:  ', metrics.log_loss(y_test, best_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = data_cleaning('data/churn_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X, y)\n",
    "best_model.predict(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}