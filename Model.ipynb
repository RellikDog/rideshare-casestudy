{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.random as rand\n",
    "from itertools import islice\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import (GradientBoostingClassifier, \n",
    "                              AdaBoostClassifier,\n",
    "                              RandomForestClassifier)\n",
    "import sklearn.datasets as datasets\n",
    "import sklearn.model_selection as cv\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.ensemble.partial_dependence import partial_dependence, plot_partial_dependence\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (9, 7)\n",
    "# from IPython.display import HTML\n",
    "from DataCleaning import data_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_cleaning('data/churn_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cv.train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=2, n_jobs=-1)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_scores(X, y, estimator, p=False, train=False):\n",
    "    if train:\n",
    "        scores = cv.cross_validate(estimator, X, y, scoring=['accuracy', 'precision', 'recall', 'neg_log_loss'], cv=5)\n",
    "        acc = np.mean(scores['test_accuracy'])\n",
    "        precision = np.mean(scores['test_precision'])\n",
    "        recall = np.mean(scores['test_recall'])\n",
    "        log_loss = -np.mean(scores['test_neg_log_loss'])\n",
    "    else:\n",
    "        y_hat = estimator.predict(X)\n",
    "        acc = metrics.accuracy_score(y, y_hat)\n",
    "        precision = metrics.precision_score(y, y_hat)\n",
    "        recall = metrics.recall_score(y, y_hat)\n",
    "        log_loss = metrics.log_loss(y, estimator.predict_proba(X))\n",
    "    if p:\n",
    "        print (\"Accuracy: {0:2.3} | Precision: {1:2.3} | Recall: {2:2.3} | Log_loss: {3:2.3}\".format(\n",
    "                                                                    acc, precision, recall, log_loss))                                                           \n",
    "    else:\n",
    "        return acc, precision, recall, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Data\n",
      "Accuracy: 0.728 | Precision: 0.75 | Recall: 0.41 | Log_loss: 0.559\n"
     ]
    }
   ],
   "source": [
    "print ('Train_Data')\n",
    "model_scores(X_train, y_train, rfc, p=True, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Data\n",
      "Accuracy: 0.735 | Precision: 0.775 | Recall: 0.424 | Log_loss: 0.555\n"
     ]
    }
   ],
   "source": [
    "print ('Test_Data')\n",
    "model_scores(X_test, y_test, rfc, p=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6242"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null\n",
    "churn = .625\n",
    "retain = .375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5742,  468],\n",
       "       [2182, 1608]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, rfc.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42427440633245384"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1608 / (2182+1608)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression(solver='lbfgs')\n",
    "LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5283,  927],\n",
       "       [1876, 1914]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, LR.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7197"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, LR.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_y = np.ones(len(y_test*y_test.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 6210],\n",
       "       [   0, 3790]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, null_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_grid = {'fit_intercept':\n",
    "                            'solver': ['lbfgs', 'saga'],\n",
    "                            'random_state': [2]}\n",
    "\n",
    "lr_gridsearch = cv.GridSearchCV(LogisticRegression(),\n",
    "                                logistic_regression_grid,\n",
    "                                n_jobs=-1,\n",
    "                                verbose=True,\n",
    "                                scoring='neg_log_loss',\n",
    "                                cv=5)\n",
    "lr_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:        \", lr_gridsearch.best_params_)\n",
    "\n",
    "best_estimator = rf_gridsearch.best_estimator_\n",
    "print('best estimator:         ', best_estimator)\n",
    "\n",
    "best_prediction = best_estimator.predict(X_test)\n",
    "print('Log_loss of best estimator:  ', metrics.log_loss(y_test, best_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_grid = {'max_depth': [1, 2, None],\n",
    "                      'max_features': ['sqrt', 'log2', None],\n",
    "                      'min_samples_split': [2, 4],\n",
    "                      'min_samples_leaf': [1, 2, 4],\n",
    "                      'bootstrap': [True, False],\n",
    "                      'n_estimators': [30, 50, 75, 100],\n",
    "                      'random_state': [2]}\n",
    "\n",
    "rf_gridsearch = cv.GridSearchCV(RandomForestClassifier(),\n",
    "                             random_forest_grid,\n",
    "                             n_jobs=-1,\n",
    "                             verbose=True,\n",
    "                             scoring='neg_log_loss',\n",
    "                             cv=5)\n",
    "rf_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:        \", rf_gridsearch.best_params_)\n",
    "\n",
    "best_estimator = rf_gridsearch.best_estimator_\n",
    "print('best estimator:         ', best_estimator)\n",
    "\n",
    "best_prediction = best_estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log_loss of best estimator:   0.6617414248021108\n"
     ]
    }
   ],
   "source": [
    "print('Score of estimator:  ', metrics.recall_score(y_test, best_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosted_grid = {'max_depth': [1, 2, None],\n",
    "                         'max_features': ['sqrt', 'log2', None],\n",
    "                         'min_samples_split': [2, 4],\n",
    "                         'min_samples_leaf': [1, 2, 4],\n",
    "                         'bootstrap': [True, False],\n",
    "                         'n_estimators': [30, 50, 75, 100],\n",
    "                         'random_state': [2]}\n",
    "\n",
    "gbr_gridsearch = cv.GridSearchCV(GradientBoostingClassifier(),\n",
    "                             gradient_boosted_grid,\n",
    "                             n_jobs=-1,\n",
    "                             verbose=True,\n",
    "                             scoring='neg_log_loss',\n",
    "                             cv=5)\n",
    "gbr_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:        \", rf_gridsearch.best_params_)\n",
    "\n",
    "best_estimator = rf_gridsearch.best_estimator_\n",
    "print('best estimator:         ', best_estimator)\n",
    "\n",
    "best_prediction = best_estimator.predict(X_test)\n",
    "print('Log_loss of best estimator:  ', metrics.log_loss(y_test, best_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = data_cleaning('data/churn_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X, y)\n",
    "best_model.predict(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
